points[i] <- sum(dice)
category[i] <- 'Three of a Kind'
} else {
points[i] <- sum(dice)
category[i] <- 'Chance'
}
}
return(list(category, points))
barplot(points)
}
RollDice(100)
a <- RollDice(100)
a
a[1]
a[2]
a[[2]][]
a[[2]]
barplot(a[[2]])
hist(a[[2]])
results <- RollDice(100)
results
barplot(results)
barplot[[results]]
points <- results[[1]]
points
unlist(results)
barplot(unlist(results))
results <- RollDice(100)
category <- results[[1]]
results <- RollDice(100)
category <- results[[1]]
points <- results[[2]]
plot(points)
plot(points, category)
plot(category)
barplot(points)
barplot(points ~ category)
barplot(category ~ points)
results <- RollDice(100)
table(points)
hist(points)
table(points, category)
table(points, category)
results <- RollDice(10000)
table(points, category)
barplot(table(points, category))
RollDice <- function(gamenumber) {
points <- c()
category <- c()
for (i in 1:gamenumber) {
dice <- sample(c(1:6), 5,  replace=TRUE)
if (length(unique(dice)) == 1) {
points[i] <- 50 #yathzee
category[i] <- 'yathzee'
} else if (length(unique(dice)) == 5) {
points[i] <- 40 # straight
category[i] <- 'straight'
} else if (length(unique(dice)) == 2) {
points[i] <- 24
category[i] <- 'full house'
} else if (length(unique(dice)) == 2 | length(unique(dice)) == 1){
points[i] <- sum(dice)
category[i] <- 'Four of a Kind'
} else if (length(unique(dice)) == 2 | length(unique(dice)) == 3) {
points[i] <- sum(dice)
category[i] <- 'Three of a Kind'
} else {
points[i] <- sum(dice)
category[i] <- 'Chance'
}
}
return(list(category, points))
table(points)
}
results <- RollDice(10000)
barplot(table(points, category))
(table(points, category)
table(points, category)
table(points, category)
results[[1]]
table(results[[1]])
barplot(table(results[[1]]))
results[[1]]
max.print
barplot(table(results[[1]]))
barplot(table(results[[1]]), main = 'Outcomes of Yatzee')
barplot(table(results[[1]]), main = 'Outcomes of Yatzee', xlim = (0,5000))
barplot(table(results[[1]]), main = 'Outcomes of Yatzee', xlim = (0 5000))
barplot(table(results[[1]]), main = 'Outcomes of Yatzee', xlim = c(0 5000))
barplot(table(results[[1]]), main = 'Outcomes of Yatzee', xlim = c(0,5000))
barplot(table(results[[1]]), main = 'Outcomes of Yatzee', xlim = c(0,4000))
barplot(table(results[[1]]), main = 'Outcomes of Yatzee', ylim = c(0,4000))
barplot(table(results[[1]]), main = 'Outcomes of Yatzee', ylim = c(0,5000))
barplot(table(results[[1]]), main = 'Outcomes of Yatzee', ylim = c(0,5000), col = 1:5)
barplot(table(results[[1]]), main = 'Outcomes of Yatzee', ylim = c(0,5000), col = 2:6)
?col
palette()
barplot(table(results[[1]]), main = 'Outcomes of Yatzee', ylim = c(0,5000), col = c('red', 'green3', 'blue', 'cyan,'black'' ))
barplot(table(results[[1]]), main = 'Outcomes of Yatzee', ylim = c(0,5000), col = c('red', 'green3', 'blue', 'cyan','black' ))
X <- matrix(c(1,1,1,1,2,3,5,7),ncol=2,nrow=4)
y <- c(3,2,4,5)
XtX <- t(X)%*%X # transpose and multiply
XtX.inv <- solve(XtX) # invert product
beta.hat <- XtX.inv%*%t(X)%*%y # estimate beta
lm(y~x)
lm(y~X)
x <- matrix(c(1,1,1,1,2,3,5,7), nrow = 4, ncol = 2)
x
x <- matrix(c(1,1,1,1,2,3,5,7), nrow = 2, ncol = 4)
x
t(x)
x <- matrix(c(1,1,1,1,2,3,5,7), nrow = 2, ncol = 4, byrow = TRUE)
x
t(x)
matrix(x, t(x))
x * t(x)
solve(t(x* t(x)))
t(x * (t(x)))
t(x * (t(x))
)
x * t(x)
solve(x * t(x))
x * t(x)
adj[abs(adj)>thr]  <- 1
adj[abs(adj)>thr]  <- 1
# Assignment 3
library(glmnet)
# Assignment 3
library(glmnet)
target <- read.table("~/Downloads/targety.txt", header = TRUE)
target
y <- target[,1]
X <- as.matrix(target[,-1])
set.seed(34)
train <- sample(1:length(y),length(y)/2)
test <- (-train)
# LASSO
fit.lasso <- glmnet(X[train,],y[train],alpha=1)
plot(fit.lasso,"lambda")
# cross validation
cv.fit.lasso <- cv.glmnet(X[train,],y[train],alpha=1)
plot(cv.fit.lasso,xlab=expression(log(lambda)))
lambda.min <- cv.fit.lasso$lambda.min
lambda.min
mean((y[test]-pred.lasso)^2)
mean((y[test]-pred.lasso)^2)
library(predict)
lambda.min <- cv.fit.lasso$lambda.min
pred.lasso <-  predict(fit.lasso,s=lambda.min ,newx=X[test,])
mean((y[test]-pred.lasso)^2)
coef.lasso <- predict(fit.lasso,type="coefficients",s=lambda.min)
length(which(coef.lasso!=0))
coef.lasso[which(coef.lasso!=0)]
# Page 1
library(glmnet)
# Page 1
library(glmnet)
target <- read.table("~/Downloads/targety.txt", header = TRUE)
y <- target[,1]
X <- as.matrix(target[,-1])
set.seed(34)
X
# LASSO REGRESSION
fit.lasso <- glmnet(X[train,],y[train],alpha=1) # alpha = 1 for LASSO method
fit.lasso
plot(fit.lasso,"lambda") # plot
# cross validation
cv.fit.lasso <- cv.glmnet(X[train,],y[train],alpha=1)
plot(cv.fit.lasso,xlab=expression(log(lambda)))
plot(cv.fit.lasso,xlab=expression(log(lambda)))  # dashed line: selected lamda chosen
lambda.min <- cv.fit.lasso$lambda.min # select lamda with min. MSE
lambda.min
pred.lasso <-  predict(fit.lasso,s=lambda.min ,newx=X[test,])
mean((y[test]-pred.lasso)^2)
target <- read.table("~/Downloads/targety.txt", header = TRUE)
y <- target[,1] # DV; amount spent
X <- as.matrix(target[,-1]) # 99 Predictors: amounts on other products
set.seed(34) # set seed to be sure
train <- sample(1:length(y),length(y)/2) # training dataset
test <- (-train) # test dataset
# LASSO REGRESSION
fit.lasso <- glmnet(X[train,],y[train],alpha=1) # alpha = 1 for LASSO method
plot(fit.lasso,"lambda") # plot lamda (penalty) for different coefficients
# cross validation
cv.fit.lasso <- cv.glmnet(X[train,],y[train],alpha=1)
plot(cv.fit.lasso,xlab=expression(log(lambda)))  # dashed line: selected lamda chosen
lambda.min <- cv.fit.lasso$lambda.min # select lamda with min. MSE
pred.lasso <-  predict(fit.lasso,s=lambda.min ,newx=X[test,])
lambda.min
lambda.min <- cv.fit.lasso$lambda.min # select lamda with min. MSE
pred.lasso <-  predict(fit.lasso,s=lambda.min ,newx=X[test,])
mean((y[test]-pred.lasso)^2) # mean squared prediction error at this lamda
coef.lasso <- predict(fit.lasso,type="coefficients",s=lambda.min)
coef.lasso
length(which(coef.lasso!=0))
coef.lasso
which(coef.lasso!=0)
length(which(coef.lasso!=0))
length(which(coef.lasso!=0)) # number of non-zero coefficients (incl. intercept)
coef.lasso[which(coef.lasso!=0)]
coef.lasso[which(coef.lasso!=0)] # display non-zero coefficients
# Page 2: Ridge Method
fit.ridge <- glmnet(X[train,],y[train],alpha=0) # ridge fit (alpha for ridge method = 0)
plot(fit.ridge,"lambda")
# cross validation
cv.fit.ridge <- cv.glmnet(X[train,],y[train],alpha=0)
plot(cv.fit.ridge,xlab=expression(log(lambda)))  # dashed line: selected lamda chosen
#determine lamda
lambda.min.ridgid <- cv.fit.ridgid$lambda.min # select lamda with min. MSE
#determine lamda
lambda.min.ridgid <- cv.fit.ridge$lambda.min # select lamda with min. MSE
lambda.min.ridgid
cv.fit.ridge$lambda.min
pred.ridgid <-  predict(fit.ridgid,s=lambda.min ,newx=X[test,])
pred.ridgid <-  predict(fit.ridgid,s=lambda.min ,newx=X[test,])
#determine lamda
lambda.min.ridgid <- cv.fit.ridge$lambda.min # select lamda with min. MSE
pred.ridgid <-  predict(fit.ridgid,s=lambda.min ,newx=X[test,])
#determine lamda
lambda.min.ridge <- cv.fit.ridge$lambda.min # select lamda with min. MSE
pred.ridge <-  predict(fit.ridge,s=lambda.min ,newx=X[test,])
pred.ridge
plot(cv.fit.ridge,xlab=expression(log(lambda)))  # dashed line: selected lamda chosen
#determine lamda
lambda.min.ridge <- cv.fit.ridge$lambda.min # select lamda with min. MSE
pred.ridge <-  predict(fit.ridge,s=lambda.min ,newx=X[test,]) # all non-zero
mean((y[test]-pred.lasso)^2) # mean squared prediction error at this lamda
mean((y[test]-pred.ridge)^2) # mean squared prediction error at this lamda
coef.ridge <- predict(fit.ridge,type="coefficients",s=lambda.min) #predicted beta coef. for those selected predictors, incl. intercept
length(which(coef.ridge!=0)) # number of non-zero coefficients (incl. intercept)
coef.ridge <- predict(fit.ridge,type="coefficients",s=lambda.min) #predicted beta coef. for those selected predictors, incl. intercept
length(which(coef.ridge!=0)) # number of non-zero coefficients (incl. intercept)
coef.ridge[which(coef.ridge!=0)] # display non-zero coefficients
# choose a given lamda for the ridge method
pred.ridge.sol <-  predict(fit.ridge,s=0.035 ,newx=X[test,]) # all non-zero
pred.ridge.sol
length(which(pred.ridge.sol!=0)) # number of non-zero coefficients (incl. intercept)
# choose a given lamda for the ridge method
pred.ridge.sol <-  predict(fit.ridge,s=0.035 ,newx=X[test,]) # all non-zero
length(which(pred.ridge.sol!=0)) # number of non-zero coefficients (incl. intercept)
# choose a given lamda for the ridge method
pred.ridge.sol <-  predict(fit.ridge,s=0.035 ,newx=X[test,]) # all non-zero
pred.ridge.sol
pred.lasso
mean(pred.lasso)
mean(pred.ridge.sol)
# choose a given lamda for the ridge method
pred.ridge.sol <-  predict(cv.fit.ridge,s=0.035 ,newx=X[test,]) # all non-zero
pred.ridge.sol
length(which(pred.ridge.sol!=0)) # number of non-zero coefficients (incl. intercept)
# choose a given lamda for the ridge method
pred.ridge.sol <-  predict(fit.ridge,s=0.035 ,newx=X[test,]) # all non-zero
length(which(coef.ridge!=0)) # number of non-zero coefficients (incl. intercept)
# choose a given lamda for the ridge method
pred.ridge.sol <-  predict(fit.ridge,s= 0.035,newx=X[test,]) # all non-zero
pred.ridge.sol
# choose a given lamda for the ridge method
pred.ridge.sol <-  predict(fit.ridge,s= 0.035,newx=X[test,]) # all non-zero
coef.ridge.sol[which(coef.ridge.sol!=0)] # display non-zero coefficients
# choose a given lamda for the ridge method
pred.ridge.sol <-  predict(fit.ridge,s= 0.035,newx=X[test,]) # all non-zero
coef.ridge.sol[which(coef.ridge.sol!=0)] # display non-zero coefficients
# choose a given lamda for the ridge method
pred.ridge.sol <-  predict(fit.ridge,s= 0.035,newx=X[test,]) # all non-zero
pred.ridge.sol[which(pred.ridge.sol!=0)] # display non-zero coefficients
length(which(pred.ridge.sol!=0)) # number of non-zero coefficients (incl. intercept)
pred.ridge.sol <-  predict(fit.ridge,s= 0.035,newx=X[test,]) # all non-zero
# Page 3: compare both methods
# use given lamda for the ridge method
pred.ridge.sol <-  predict(fit.ridge,s= 0.035,newx=X[test,])
pred.ridge.sol[which(pred.ridge.sol!=0)] # display non-zero coefficients
length(which(pred.ridge.sol!=0)) # number of non-zero coefficients (incl. intercept)
# Page 3: compare both methods
# use given lamda for the ridge method
pred.ridge.sol <-  predict(fit.lasso,s= 0.035,newx=X[test,])
# Page 3: compare both methods
# use given lamda for the ridge method
pred.lasso.sol <-  predict(fit.lasso,s= 0.035,newx=X[test,])
length(which(pred.lasso.sol!=0)) # number of non-zero coefficients (incl. intercept)
# Page 3: compare both methods
# use given lamda for the ridge method
pred.lasso.sol <-  predict(fit.lasso,s= 0.035,newx=X[test,])
length(which(pred.lasso.sol!=0)) # number of non-zero coefficients (incl. intercept)
# use given lamda for the ridge method
pre.ridge.sol <-  predict(fit.ridge,s= 0.035,newx=X[test,])
pred.ridge.sol[which(pred.ridge.sol!=0)] # display non-zero coefficients
length(which(pred.ridge.sol!=0)) # number of non-zero coefficients (incl. intercept)
# use given lamda for the ridge method
pre.ridge.sol <-  predict(fit.ridge,s= 0.035,newx=X[test,]);
pre.ridge.sol <-  predict(fit.ridge,s= 0.035,newx=X[test,]);
# Page 3: compare both methods
# use given lamda for the ridge method
pred.lasso.sol <-  predict(fit.lasso,s= 0.035,newx=X[test,]);
pred.lasso.sol[which(pred.lasso.sol!=0)] # display non-zero coefficients;
length(which(pred.lasso.sol!=0)) # number of non-zero coefficients (incl. intercept)
# use given lamda for the ridge method
pre.ridge.sol <-  predict(fit.ridge,s= 0.035,newx=X[test,]);
pred.ridge.sol[which(pred.ridge.sol!=0)]; # display non-zero coefficients
length(which(pred.ridge.sol!=0)) # number of non-zero coefficients (incl. intercept)
# Page 3: compare both methods
# use given lamda for the lasso method
pred.lasso.sol <-  predict(fit.lasso,s= 0.035,newx=X[test,]);
#pred.lasso.sol[which(pred.lasso.sol!=0)] # display non-zero coefficients;
length(which(pred.lasso.sol!=0)) # number of non-zero coefficients (incl. intercept)
# use given lamda for the ridge method
pre.ridge.sol <-  predict(fit.ridge,s= 0.035,newx=X[test,]);
#pred.ridge.sol[which(pred.ridge.sol!=0)] # display non-zero coefficients
length(which(pred.ridge.sol!=0)) # number of non-zero coefficients (incl. intercept)
clc
# Page 3: compare both methods
# use given lamda for the lasso method
pred.lasso.sol <-  predict(fit.lasso,s= 0.035,newx=X[test,]);
#pred.lasso.sol[which(pred.lasso.sol!=0)] # display non-zero coefficients;
length(which(pred.lasso.sol!=0)) # number of non-zero coefficients (incl. intercept)
# use given lamda for the ridge method
pre.ridge.sol <-  predict(fit.ridge,s= 0.035,newx=X[test,]);
#pred.ridge.sol[which(pred.ridge.sol!=0)] # display non-zero coefficients
length(which(pred.ridge.sol!=0)) # number of non-zero coefficients (incl. intercept)
# Page 2: Ridge Method
# fit ridge
fit.ridge <- glmnet(X[train,],y[train],alpha=0) # ridge fit (alpha for ridge method = 0)
# use given lamda for the ridge method
pre.ridge.sol <-  predict(fit.ridge,s= 0.035,newx=X[test,]);
#pred.ridge.sol[which(pred.ridge.sol!=0)] # display non-zero coefficients
length(which(pred.ridge.sol!=0)) # number of non-zero coefficients (incl. intercept)
pred.ridge <-  predict(fit.ridge,s=lambda.min ,newx=X[test,]) # all non-zero
# Page 1: Running Lasso Method
library(glmnet)
target <- read.table("~/Downloads/targety.txt", header = TRUE)
y <- target[,1] # DV; amount spent
X <- as.matrix(target[,-1]) # 99 Predictors: amounts on other products
set.seed(34) # set seed to be sure
train <- sample(1:length(y),length(y)/2) # training dataset
test <- (-train) # test dataset
# LASSO REGRESSION
fit.lasso <- glmnet(X[train,],y[train],alpha=1) # alpha = 1 for LASSO method
plot(fit.lasso,"lambda") # plot lamda (penalty) for different coefficients
# cross validation
cv.fit.lasso <- cv.glmnet(X[train,],y[train],alpha=1)
plot(cv.fit.lasso,xlab=expression(log(lambda)))  # dashed line: selected lamda chosen
lambda.min <- cv.fit.lasso$lambda.min # select lamda with min. MSE
pred.lasso <-  predict(fit.lasso,s=lambda.min ,newx=X[test,])
mean((y[test]-pred.lasso)^2) # mean squared prediction error at this lamda
coef.lasso <- predict(fit.lasso,type="coefficients",s=lambda.min) #predicted beta coef. for those selected predictors, incl. intercept
length(which(coef.lasso!=0)) # number of non-zero coefficients (incl. intercept)
coef.lasso[which(coef.lasso!=0)] # display non-zero coefficients
# Page 2: Ridge Method
# fit ridge
fit.ridge <- glmnet(X[train,],y[train],alpha=0) # ridge fit (alpha for ridge method = 0)
plot(fit.ridge,"lambda") # all coef. are non-zero
# cross validation
cv.fit.ridge <- cv.glmnet(X[train,],y[train],alpha=0)
plot(cv.fit.ridge,xlab=expression(log(lambda)))  # dashed line: selected lamda chosen
#determine lamda
lambda.min.ridge <- cv.fit.ridge$lambda.min # select lamda with min. MSE
pred.ridge <-  predict(fit.ridge,s=lambda.min ,newx=X[test,]) # all non-zero
mean((y[test]-pred.ridge)^2) # mean squared prediction error at this lamda
coef.ridge <- predict(fit.ridge,type="coefficients",s=lambda.min) #predicted beta coef. for those selected predictors, incl. intercept
length(which(coef.ridge!=0)) # number of non-zero coefficients (incl. intercept)
coef.ridge[which(coef.ridge!=0)] # display non-zero coefficients
# Page 3: compare both methods
# use given lamda for the lasso method
pred.lasso.sol <-  predict(fit.lasso,s= 0.035,newx=X[test,]);
#pred.lasso.sol[which(pred.lasso.sol!=0)] # display non-zero coefficients;
length(which(pred.lasso.sol!=0)) # number of non-zero coefficients (incl. intercept)
# use given lamda for the ridge method
pre.ridge.sol <-  predict(fit.ridge,s= 0.035,newx=X[test,]);
#pred.ridge.sol[which(pred.ridge.sol!=0)] # display non-zero coefficients
length(which(pred.ridge.sol!=0)) # number of non-zero coefficients (incl. intercept)
pred.ridge <-  predict(fit.ridge,s=lambda.min ,newx=X[test,]) # all non-zero
pred.ridge
coef.ridge <- predict(fit.ridge,type="coefficients",s=lambda.min) #predicted beta coef. for those selected predictors, incl. intercept
coef.ridge
# Page 3: compare both methods
pred.ridge <-  predict(fit.ridge,s=0.035 ,newx=X[test,]) # estimated lamdas
pred.ridge
lambda.min
lambda.min
lambda.min.ridge
# use given lamda for the ridge method
pre.ridge.sol <-  predict(fit.ridge,s= 0.035,newx=X[test,], type = "coefficients");
#pred.ridge.sol[which(pred.ridge.sol!=0)] # display non-zero coefficients
length(which(pred.ridge.sol!=0)) # number of non-zero coefficients (incl. intercept)
# use given lamda for the ridge method
pre.ridge.sol <-  predict(fit.ridge,s= 0.035,newx=X[test,], type = "coefficients");
#pred.ridge.sol[which(pred.ridge.sol!=0)] # display non-zero coefficients
length(which(pred.ridge.sol!=0)) # number of non-zero coefficients (incl. intercept)
coef.ridge <- predict(fit.ridge,type="coefficients",s=lambda.min.ridge) #predicted beta coef. for those selected predictors, incl. intercept
pred.ridge <-  predict(fit.ridge,s=lambda.min.ridge ,newx=X[test,]) # estimated lamdas
mean((y[test]-pred.ridge)^2) # mean squared prediction error at this lamda
coef.ridge <- predict(fit.ridge,type="coefficients",s=lambda.min.ridge) #predicted beta coef. for those selected predictors, incl. intercept
length(which(coef.ridge!=0)) # number of non-zero coefficients (incl. intercept)
coef.ridge[which(coef.ridge!=0)] # display non-zero coefficients
# Page 3: compare both methods
pred.ridge <-  predict(fit.ridge,s=0.035 ,newx=X[test,]) # estimated lamdas
# use given lamda for the ridge method
pre.ridge.sol <-  predict(fit.ridge,s= 0.035,newx=X[test,], type = "coefficients");
#pred.ridge.sol[which(pred.ridge.sol!=0)] # display non-zero coefficients
length(which(pred.ridge.sol!=0)) # number of non-zero coefficients (incl. intercept)
# Page 3: compare both methods
fit.ridge <- glmnet(X[train,],y[train],alpha=0) # ridge fit (alpha for ridge method = 0)
plot(fit.ridge,"lambda") # all coef. are non-zero
lambda.min.ridge <- cv.fit.ridge$lambda.min # select lamda with min. MSE
pred.ridge <-  predict(fit.ridge,s=lambda.min.ridge ,newx=X[test,]) # estimated lamdas
pred.ridge <-  predict(fit.ridge,s=0.035,newx=X[test,]) # estimated lamdas
pred.ridge
fit.ridge
test
train <- sample(1:length(y),length(y)/2) # training dataset
test <- (-train) # test dataset
test
target <- read.table("~/Downloads/targety.txt", header = TRUE)
y <- target[,1] # DV; amount spent
X <- as.matrix(target[,-1]) # 99 Predictors: amounts on other products
X
train <- sample(1:length(y),length(y)/2) # training dataset
test <- (-train) # test dataset
train
test
# Page 3: compare both methods
fit.ridge <- glmnet(X[train,],y[train],alpha=0) # ridge fit (alpha for ridge method = 0)
plot(fit.ridge,"lambda") # all coef. are non-zero
lambda.min.ridge <- cv.fit.ridge$lambda.min # select lamda with min. MSE
pred.ridge <-  predict(fit.ridge,s=0.035,newx=X[test,]) # estimated lamdas
pred.ridge <-  predict(fit.ridge,s=0.035 ,newx=X[test,]) # estimated lamdas
# Page 3: compare both methods
fit.ridge <- glmnet(X[train,],y[train],alpha=0) # ridge fit (alpha for ridge method = 0)
plot(fit.ridge,"lambda") # all coef. are non-zero
lambda.min.ridge <- cv.fit.ridge$lambda.min # select lamda with min. MSE
pred.ridge <-  predict(fit.ridge,s=0.035,newx=X[test,]) # estimated lamdas
pred.ridge
pred.ridge <-  predict(fit.ridge,s=0.035) # estimated lamdas
coef.ridge <- predict(fit.ridge,type="coefficients",s=0.035) #predicted beta coef. for those selected predictors, incl. intercept
coef.ridge[which(coef.ridge!=0)] # display non-zero coefficients
pred.ridge <-  predict(fit.ridge,s=0.035 ,newx=X[test,]) # estimated lamdas
length(which(coef.ridge!=0)) # number of non-zero coefficients (incl. intercept)
coef.ridge
mean(coef.ridge)
# Page 3: compare both methods
#perform ridge with given s = 0.035
fit.ridge.sol <- glmnet(X[train,],y[train],alpha=0) # ridge fit (alpha for ridge method = 0)
plot(fit.ridge.sol,"lambda") # all coef. are non-zero
pred.ridge.sol <-  predict(fit.ridge.sol,s=0.035,newx=X[test,]) # estimated lamdas
coef.ridge.sol <- predict(fit.ridge.sol,type="coefficients",s=0.035) #predicted beta coef. for those selected predictors, incl. intercept
coef.ridge.sol[which(coef.ridge.sol!=0)] # display non-zero coefficients
length(which(coef.ridge.sol!=0)) # number of non-zero coefficients (incl. intercept)
#determine lamda
lambda.min.ridge <- cv.fit.ridge$lambda.min # select lamda with min. MSE
pred.ridge <-  predict(fit.ridge,s=lambda.min.ridge ,newx=X[test,]) # estimated lamdas
mean((y[test]-pred.ridge)^2) # mean squared prediction error at this lamda
coef.ridge <- predict(fit.ridge,type="coefficients",s=lambda.min.ridge) #predicted beta coef. for those selected predictors, incl. intercept
length(which(coef.ridge!=0)) # number of non-zero coefficients (incl. intercept)
coef.ridge[which(coef.ridge!=0)] # display non-zero coefficients
# compare whether they are different
mean(coef.ridge.sol)
mean(coef.ridge)
coef.ridge
coef.ridge.sol
coef.ridge
coef.ridge.sol
fit.ridge.sol <- glmnet(X[train,],y[train],alpha=0) # ridge fit (alpha for ridge method = 0)
plot(fit.ridge.sol,"lambda") # all coef. are non-zero
pred.ridge.sol <-  predict(fit.ridge.sol,s=0.035,newx=X[test,]) # estimated lamdas
coef.ridge.sol <- predict(fit.ridge.sol,type="coefficients",s=0.035) #predicted beta coef. for those selected predictors, incl. intercept
coef.ridge.sol[which(coef.ridge.sol!=0)] # display non-zero coefficients
length(which(coef.ridge.sol!=0)) # number of non-zero coefficients (incl. intercept)
install.packages('dmetar')
library(dmetar)
data <- read.spss("/Users/rfreichel/Downloads/spanish.sav", to.data.frame=TRUE) #read .sav file with package foreign
library('foreign')
data <- read.spss("/Users/rfreichel/Downloads/spanish.sav", to.data.frame=TRUE) #read .sav file with package foreign
data <- read.spss("spanish.sav", reencode='utf-8', to.data.frame =TRUE)
data <- read.spss("/Users/rfreichel/Downloads/spanish.sav", reencode='utf-8', to.data.frame =TRUE)
data
View(data)
data <- read.spss("DTMA0093.sav", to.data.frame =TRUE) #reencode='utf-8'
data <- read.spss("DTMA0093.sav", to.data.frame =TRUE) #reencode='utf-8'
library('foreign')
data <- read.spss("DTMA0093.sav", to.data.frame =TRUE) #reencode='utf-8'
data <- read.spss("DTMA0093.sav", to.data.frame =TRUE) #reencode='utf-8'
data <- read.spss("/Users/rfreichel/Downloads/DTMA0093.sav", to.data.frame =TRUE) #reencode='utf-8'
View(data)
install.packages(c("backports", "boot", "broom", "callr", "car", "caret", "class", "cli", "dbplyr", "digest", "dplyr", "forcats", "foreach", "fs", "ggplot2", "ggraph", "glue", "gplots", "graphlayouts", "gtools", "Hmisc", "huge", "igraph", "janitor", "jsonlite", "KernSmooth", "knitr", "lattice", "lava", "lifecycle", "lme4", "lubridate", "MASS", "mgm", "mime", "mnormt", "ModelMetrics", "modelr", "nlme", "nloptr", "nnet", "openxlsx", "pbkrtest", "pillar", "plotrix", "plyr", "pROC", "processx", "ps", "purrr", "quantreg", "Rcpp", "RcppArmadillo", "recipes", "reshape2", "rlang", "rstatix", "rstudioapi", "sp", "spatial", "SQUAREM", "stringi", "survival", "tibble", "tidyr", "tidyselect", "tinytex", "vctrs", "withr", "xfun", "xml2", "yaml"))
install.packages(c("backports", "boot", "broom", "callr", "car", "caret", "class", "cli", "dbplyr", "digest", "dplyr", "forcats", "foreach", "fs", "ggplot2", "ggraph", "glue", "gplots", "graphlayouts", "gtools", "Hmisc", "huge", "igraph", "janitor", "jsonlite", "KernSmooth", "knitr", "lattice", "lava", "lifecycle", "lme4", "lubridate", "MASS", "mgm", "mime", "mnormt", "ModelMetrics", "modelr", "nlme", "nloptr", "nnet", "openxlsx", "pbkrtest", "pillar", "plotrix", "plyr", "pROC", "processx", "ps", "purrr", "quantreg", "Rcpp", "RcppArmadillo", "recipes", "reshape2", "rlang", "rstatix", "rstudioapi", "sp", "spatial", "SQUAREM", "stringi", "survival", "tibble", "tidyr", "tidyselect", "tinytex", "vctrs", "withr", "xfun", "xml2", "yaml"))
install.packages(c("backports", "boot", "broom", "callr", "car", "caret", "class", "cli", "dbplyr", "digest", "dplyr", "forcats", "foreach", "fs", "ggplot2", "ggraph", "glue", "gplots", "graphlayouts", "gtools", "Hmisc", "huge", "igraph", "janitor", "jsonlite", "KernSmooth", "knitr", "lattice", "lava", "lifecycle", "lme4", "lubridate", "MASS", "mgm", "mime", "mnormt", "ModelMetrics", "modelr", "nlme", "nloptr", "nnet", "openxlsx", "pbkrtest", "pillar", "plotrix", "plyr", "pROC", "processx", "ps", "purrr", "quantreg", "Rcpp", "RcppArmadillo", "recipes", "reshape2", "rlang", "rstatix", "rstudioapi", "sp", "spatial", "SQUAREM", "stringi", "survival", "tibble", "tidyr", "tidyselect", "tinytex", "vctrs", "withr", "xfun", "xml2", "yaml"))
install.packages(c("backports", "boot", "broom", "callr", "car", "caret", "class", "cli", "dbplyr", "digest", "dplyr", "forcats", "foreach", "fs", "ggplot2", "ggraph", "glue", "gplots", "graphlayouts", "gtools", "Hmisc", "huge", "igraph", "janitor", "jsonlite", "KernSmooth", "knitr", "lattice", "lava", "lifecycle", "lme4", "lubridate", "MASS", "mgm", "mime", "mnormt", "ModelMetrics", "modelr", "nlme", "nloptr", "nnet", "openxlsx", "pbkrtest", "pillar", "plotrix", "plyr", "pROC", "processx", "ps", "purrr", "quantreg", "Rcpp", "RcppArmadillo", "recipes", "reshape2", "rlang", "rstatix", "rstudioapi", "sp", "spatial", "SQUAREM", "stringi", "survival", "tibble", "tidyr", "tidyselect", "tinytex", "vctrs", "withr", "xfun", "xml2", "yaml"))
install.packages(c("backports", "boot", "broom", "callr", "car", "caret", "class", "cli", "dbplyr", "digest", "dplyr", "forcats", "foreach", "fs", "ggplot2", "ggraph", "glue", "gplots", "graphlayouts", "gtools", "Hmisc", "huge", "igraph", "janitor", "jsonlite", "KernSmooth", "knitr", "lattice", "lava", "lifecycle", "lme4", "lubridate", "MASS", "mgm", "mime", "mnormt", "ModelMetrics", "modelr", "nlme", "nloptr", "nnet", "openxlsx", "pbkrtest", "pillar", "plotrix", "plyr", "pROC", "processx", "ps", "purrr", "quantreg", "Rcpp", "RcppArmadillo", "recipes", "reshape2", "rlang", "rstatix", "rstudioapi", "sp", "spatial", "SQUAREM", "stringi", "survival", "tibble", "tidyr", "tidyselect", "tinytex", "vctrs", "withr", "xfun", "xml2", "yaml"))
install.packages(c("backports", "boot", "broom", "callr", "car", "caret", "class", "cli", "dbplyr", "digest", "dplyr", "forcats", "foreach", "fs", "ggplot2", "ggraph", "glue", "gplots", "graphlayouts", "gtools", "Hmisc", "huge", "igraph", "janitor", "jsonlite", "KernSmooth", "knitr", "lattice", "lava", "lifecycle", "lme4", "lubridate", "MASS", "mgm", "mime", "mnormt", "ModelMetrics", "modelr", "nlme", "nloptr", "nnet", "openxlsx", "pbkrtest", "pillar", "plotrix", "plyr", "pROC", "processx", "ps", "purrr", "quantreg", "Rcpp", "RcppArmadillo", "recipes", "reshape2", "rlang", "rstatix", "rstudioapi", "sp", "spatial", "SQUAREM", "stringi", "survival", "tibble", "tidyr", "tidyselect", "tinytex", "vctrs", "withr", "xfun", "xml2", "yaml"))
install.packages(c("backports", "boot", "broom", "callr", "car", "caret", "class", "cli", "dbplyr", "digest", "dplyr", "forcats", "foreach", "fs", "ggplot2", "ggraph", "glue", "gplots", "graphlayouts", "gtools", "Hmisc", "huge", "igraph", "janitor", "jsonlite", "KernSmooth", "knitr", "lattice", "lava", "lifecycle", "lme4", "lubridate", "MASS", "mgm", "mime", "mnormt", "ModelMetrics", "modelr", "nlme", "nloptr", "nnet", "openxlsx", "pbkrtest", "pillar", "plotrix", "plyr", "pROC", "processx", "ps", "purrr", "quantreg", "Rcpp", "RcppArmadillo", "recipes", "reshape2", "rlang", "rstatix", "rstudioapi", "sp", "spatial", "SQUAREM", "stringi", "survival", "tibble", "tidyr", "tidyselect", "tinytex", "vctrs", "withr", "xfun", "xml2", "yaml"))
install.packages(c("backports", "boot", "broom", "callr", "car", "caret", "class", "cli", "dbplyr", "digest", "dplyr", "forcats", "foreach", "fs", "ggplot2", "ggraph", "glue", "gplots", "graphlayouts", "gtools", "Hmisc", "huge", "igraph", "janitor", "jsonlite", "KernSmooth", "knitr", "lattice", "lava", "lifecycle", "lme4", "lubridate", "MASS", "mgm", "mime", "mnormt", "ModelMetrics", "modelr", "nlme", "nloptr", "nnet", "openxlsx", "pbkrtest", "pillar", "plotrix", "plyr", "pROC", "processx", "ps", "purrr", "quantreg", "Rcpp", "RcppArmadillo", "recipes", "reshape2", "rlang", "rstatix", "rstudioapi", "sp", "spatial", "SQUAREM", "stringi", "survival", "tibble", "tidyr", "tidyselect", "tinytex", "vctrs", "withr", "xfun", "xml2", "yaml"))
install.packages(c("backports", "boot", "broom", "callr", "car", "caret", "class", "cli", "dbplyr", "digest", "dplyr", "forcats", "foreach", "fs", "ggplot2", "ggraph", "glue", "gplots", "graphlayouts", "gtools", "Hmisc", "huge", "igraph", "janitor", "jsonlite", "KernSmooth", "knitr", "lattice", "lava", "lifecycle", "lme4", "lubridate", "MASS", "mgm", "mime", "mnormt", "ModelMetrics", "modelr", "nlme", "nloptr", "nnet", "openxlsx", "pbkrtest", "pillar", "plotrix", "plyr", "pROC", "processx", "ps", "purrr", "quantreg", "Rcpp", "RcppArmadillo", "recipes", "reshape2", "rlang", "rstatix", "rstudioapi", "sp", "spatial", "SQUAREM", "stringi", "survival", "tibble", "tidyr", "tidyselect", "tinytex", "vctrs", "withr", "xfun", "xml2", "yaml"))
install.packages(c("backports", "boot", "broom", "callr", "car", "caret", "class", "cli", "dbplyr", "digest", "dplyr", "forcats", "foreach", "fs", "ggplot2", "ggraph", "glue", "gplots", "graphlayouts", "gtools", "Hmisc", "huge", "igraph", "janitor", "jsonlite", "KernSmooth", "knitr", "lattice", "lava", "lifecycle", "lme4", "lubridate", "MASS", "mgm", "mime", "mnormt", "ModelMetrics", "modelr", "nlme", "nloptr", "nnet", "openxlsx", "pbkrtest", "pillar", "plotrix", "plyr", "pROC", "processx", "ps", "purrr", "quantreg", "Rcpp", "RcppArmadillo", "recipes", "reshape2", "rlang", "rstatix", "rstudioapi", "sp", "spatial", "SQUAREM", "stringi", "survival", "tibble", "tidyr", "tidyselect", "tinytex", "vctrs", "withr", "xfun", "xml2", "yaml"))
install.packages(c("backports", "boot", "broom", "callr", "car", "caret", "class", "cli", "dbplyr", "digest", "dplyr", "forcats", "foreach", "fs", "ggplot2", "ggraph", "glue", "gplots", "graphlayouts", "gtools", "Hmisc", "huge", "igraph", "janitor", "jsonlite", "KernSmooth", "knitr", "lattice", "lava", "lifecycle", "lme4", "lubridate", "MASS", "mgm", "mime", "mnormt", "ModelMetrics", "modelr", "nlme", "nloptr", "nnet", "openxlsx", "pbkrtest", "pillar", "plotrix", "plyr", "pROC", "processx", "ps", "purrr", "quantreg", "Rcpp", "RcppArmadillo", "recipes", "reshape2", "rlang", "rstatix", "rstudioapi", "sp", "spatial", "SQUAREM", "stringi", "survival", "tibble", "tidyr", "tidyselect", "tinytex", "vctrs", "withr", "xfun", "xml2", "yaml"))
setwd("/Users/rfreichel/Documents/GitHub/eegstats") #keep cheatsheet in downloads folder
ReadingIn <- function(x) { #myFunction is name of function, x is input of function -> use value of x here in function(3), then x = 3
code_body #Insert code to be carried out when calling the function
}
# print error if not in the right format
if (!is.matrix(x)) {
stop('The input should be a matrix of shape ERP signal x time!')
}
ReadingIn <- function(x) { #myFunction is name of function, x is input of function -> use value of x here in function(3), then x = 3
if (!is.matrix(x)) {
stop('The input should be a matrix of shape ERP signal x time!')
} #Insert code to be carried out when calling the function
}
ReadingIn(x = 4)
ReadingIn(x = matrix(NA,2,2))
library(ggplot2)
install.packages(ggplot2)
install.packages('ggplot2')
library(ggplot2)
